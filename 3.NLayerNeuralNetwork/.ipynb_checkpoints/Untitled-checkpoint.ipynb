{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self,model, acti_func, d_acti_func,input_dim = None, output_dim = None, first_layer=False, last_layer=False,learning_rate = 0.0075):\n",
    "        self.model = model\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "\n",
    "        self.A = None\n",
    "        self.Z = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        self.dA = None # actually gradient of output of prev layer\n",
    "        self.dZ = None\n",
    "        \n",
    "        self.first_layer = first_layer\n",
    "        self.last_layer = last_layer\n",
    "        \n",
    "        self.acti_func = acti_func\n",
    "        self.d_acti_func = d_acti_func\n",
    "        \n",
    "        self.next_layer = None\n",
    "        self.prev_layer = None\n",
    "        \n",
    "    def random_initialize(self):\n",
    "        self.W = np.random.randn(self.output_dim, self.input_dim)/np.sqrt(self.input_dim)  #*np.sqrt(2/self.input_dim)\n",
    "        #self.W = np.random.randn(self.output_dim, self.input_dim)*0.01\n",
    "        self.b = np.zeros(shape=(self.output_dim, 1))\n",
    "        \n",
    "    def forward_propagate(self):\n",
    "        if self.first_layer:\n",
    "            prev_A = self.model.data\n",
    "        else:\n",
    "            prev_A = self.prev_layer.A\n",
    "\n",
    "        self.Z = self.W.dot(prev_A) + self.b\n",
    "                \n",
    "        self.A = self.acti_func(self.Z)\n",
    "        \n",
    "    def backward_propagate(self):\n",
    "        if self.first_layer:\n",
    "            prev_A = self.model.data\n",
    "        else:\n",
    "            prev_A = self.prev_layer.A\n",
    "            \n",
    "        if self.last_layer:\n",
    "            next_dA = self.model.calculate_cost_derivative(self.A)\n",
    "        else:\n",
    "            next_dA = self.next_layer.dA\n",
    "\n",
    "        m = prev_A.shape[1]\n",
    "                \n",
    "        self.dZ = next_dA*self.d_acti_func(self.Z)\n",
    "        self.dW = self.dZ.dot(prev_A.T)/m\n",
    "        self.db = np.sum(self.dZ, axis=1, keepdims=True)/m\n",
    "        self.dA = self.W.T.dot(self.dZ)\n",
    "        \n",
    "    def optimize(self):\n",
    "        self.W -= self.learning_rate*self.dW\n",
    "        self.b -= self.learning_rate*self.db\n",
    "\n",
    "\n",
    "#description = [{\"layer_size\" : 10, \"activation\" : \"sigmoid\"}, \n",
    "#               {\"layer_size\" : 20, \"activation\" : \"sigmoid\"}, \n",
    "#               {\"layer_size\" : 20, \"activation\" : \"sigmoid\"},\n",
    "#               {\"layer_size\" : 1, \"activation\" : \"sigmoid\"}]\n",
    "\n",
    "class NN():\n",
    "    def __init__(self, description, input_size, cost_function, train_data = None, train_labels = None,learning_rate = 0.0075):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = self.create_architecture(description, input_size)\n",
    "        self.data = train_data\n",
    "        self.labels = train_labels\n",
    "        \n",
    "        # cost_function(y, y_hat)\n",
    "        self.cost_function, self.d_cost_function = cost_functions[cost_function]\n",
    "        \n",
    "    def calculate_cost(self, y_hat):\n",
    "        return self.cost_function(self.labels, y_hat)\n",
    "    \n",
    "    def calculate_cost_derivative(self, y_hat):\n",
    "        return self.d_cost_function(self.labels, y_hat)\n",
    "        \n",
    "    def calculate_accuracy(self,test_data, test_labels):\n",
    "        # Works for binary input right now\n",
    "        self.data = test_data\n",
    "        self.labels = test_labels\n",
    "        \n",
    "        self.forward_pass()\n",
    "        \n",
    "        y_hat = self.layers[-1].A\n",
    "        \n",
    "        pred = np.where(y_hat > 0.5, 1, 0)\n",
    "            \n",
    "        return (pred == self.labels).mean()\n",
    "                \n",
    "        \n",
    "    def create_architecture(self, description, input_size):\n",
    "        layers = []\n",
    "        \n",
    "        for index, descr in enumerate(description):\n",
    "            print(index)\n",
    "            input_dim = input_size if index == 0 else layers[-1].output_dim\n",
    "            output_dim = descr[\"layer_size\"]\n",
    "            activ, d_activ = activation_functions[descr[\"activation\"]]\n",
    "            \n",
    "            layer = Layer(self, activ, d_activ,input_dim, output_dim,\n",
    "                         first_layer=(index ==  0 ), last_layer = (index == len(description) - 1),learning_rate = self.learning_rate)\n",
    "            \n",
    "            # set pointers\n",
    "            if index != 0:\n",
    "                layers[-1].next_layer = layer\n",
    "                layer.prev_layer = layers[-1]\n",
    "                \n",
    "            layers.append(layer)\n",
    "    \n",
    "        # \"layers\" is populated now. Initialize weights\n",
    "        for layer in layers:\n",
    "            layer.random_initialize()\n",
    "            \n",
    "        return layers\n",
    "    \n",
    "    def add_data(self, train_data, train_labels):\n",
    "        self.data = train_data\n",
    "        self.labels = train_labels\n",
    "        \n",
    "    def forward_pass(self):\n",
    "        for layer in self.layers:            \n",
    "            layer.forward_propagate()\n",
    "            \n",
    "    def backward_pass(self):\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward_propagate()\n",
    "            \n",
    "    def optimize(self):\n",
    "        for layer in self.layers:\n",
    "            layer.optimize()\n",
    "    \n",
    "    def train(self, epocs):\n",
    "        history = []\n",
    "        \n",
    "        for i in range(epocs):\n",
    "            self.forward_pass()\n",
    "        \n",
    "            cost = self.calculate_cost(self.layers[-1].A)\n",
    "            history.append(cost)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print (\"Cost after iteration %i: %f\" %(i, cost))        \n",
    "            self.backward_pass()\n",
    "                        \n",
    "            self.optimize()\n",
    "\n",
    "        \n",
    "        # Training done. Return history\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy_sigmoid(y, y_hat):\n",
    "    m = y.shape[1]\n",
    "    #cost = np.sum(y*np.log(y_hat) + (1-y)*np.log(1 - y_hat)) / (-1*m)\n",
    "    cost = (1./m) * (-np.dot(y,np.log(y_hat).T) - np.dot(1-y, np.log(1-y_hat).T))\n",
    "    \n",
    "    # So that we have a real number at the end instead of a singleton; e.g. [[3]] => 3\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def cross_entropy_softmax(y, y_hat):\n",
    "    # y is a vector of dimension [1 x num_of_inputs]\n",
    "    # IT IS NOT ONE HOT VECTOR !!!\n",
    "        \n",
    "    num_inputs = y_hat.shape[1]\n",
    "    \n",
    "    # get the probabilities indexed by classes, y_hat\n",
    "    probs = y_hat[y.squeeze(), range(num_inputs)]\n",
    "\n",
    "    \n",
    "    log_probs = np.log(probs)\n",
    "    \n",
    "    cost = np.sum(log_probs)/(-1*num_inputs)\n",
    "    \n",
    "    # So that we have a real number at the end instead of a singleton; e.g. [[3]] => 3\n",
    "    cost = cost.squeeze()\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def cross_entropy_sigmoid_derivative(y, y_hat):\n",
    "    m = y.shape[1]\n",
    "    return (-(np.divide(y, y_hat) - np.divide(1 - y, 1 - y_hat)))\n",
    "\n",
    "def cross_entropy_softmax_derivative(y, y_hat):\n",
    "    # y is a vector of dimension [1 x num_of_inputs]\n",
    "    # IT IS NOT ONE HOT VECTOR !!!\n",
    "\n",
    "    num_inputs = y_hat.shape[1]\n",
    "    \n",
    "    d = np.zeros(y_hat.shape)\n",
    "    \n",
    "    d[y, range(num_inputs)] = 1/y_hat[y, range(num_inputs)]\n",
    "    \n",
    "    return d/num_inputs\n",
    "\n",
    "def mean_squared(y, y_hat):\n",
    "    return  np.sum((y - y_hat)**2 ).squeeze() / (y_hat.shape[1]*2)\n",
    "\n",
    "def d_mean_squared(y, y_hat):\n",
    "    return (y_hat - y)\n",
    "\n",
    "\n",
    "cost_functions = {\"cross_entropy_sigmoid\" : (cross_entropy_sigmoid, cross_entropy_sigmoid_derivative),\n",
    "                 \"cross_entropy_softmax\" : (cross_entropy_softmax, cross_entropy_softmax_derivative),\n",
    "                  \"mean_squared\" : (mean_squared, d_mean_squared)\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    \n",
    "    return s\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    \n",
    "    return s*(1-s)\n",
    "\n",
    "def relu(x):\n",
    "    r = np.maximum(0,x)\n",
    "    \n",
    "    assert(x.shape == r.shape)\n",
    "    \n",
    "    return r\n",
    "\n",
    "def d_relu(x):\n",
    "    r = np.where(x > 0, 1, 0)\n",
    "    \n",
    "    assert(x.shape == r.shape)\n",
    "    \n",
    "    return r\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def d_tanh(x):\n",
    "    d = tanh(x)\n",
    "    return 1 - d*d\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "def d_linear(x):\n",
    "    return np.ones(shape=x.shape)\n",
    "\n",
    "activation_functions = {\"sigmoid\" : (sigmoid, d_sigmoid) , \"relu\" : (relu, d_relu), \"tanh\" : (tanh, d_tanh), \"linear\" : (linear, d_linear)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer, load_digits, load_iris\n",
    "\n",
    "def split_dataset(X,y):\n",
    "    # size of X : [num_input x num_dimension]\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
    "    train_X = train_X.T\n",
    "    test_X = test_X.T\n",
    "    \n",
    "    \n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "def normalize_data(train_X, test_X):\n",
    "    means = np.mean(train_X, axis = 1, keepdims=True)\n",
    "    std_dev = np.std(train_X, axis = 1, keepdims=True)\n",
    "\n",
    "    train_X = (train_X - means)/std_dev\n",
    "    test_X = (test_X - means)/std_dev\n",
    "    \n",
    "    return train_X, test_X, means, std_dev\n",
    "\n",
    "\n",
    "# From https://machinelearningmastery.com/generate-test-datasets-python-scikit-learn/\n",
    "from sklearn.datasets.samples_generator import make_blobs, make_moons, make_regression,make_s_curve, make_friedman1\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "# # generate 2d classification dataset\n",
    "# X_1,y_1 = make_moons(n_samples=1000)\n",
    "# y_1 = np.array(y_1).reshape((len(y_1),1))\n",
    "# #X, y = make_blobs(n_samples=1000, centers=2, n_features=2)\n",
    "\n",
    "# # scatter plot, dots colored by class value\n",
    "# df = DataFrame(dict(x=X_1[:,0], y=X_1[:,1], label=y_1.squeeze()))\n",
    "# colors = {0:'red', 1:'blue', 2:'green'}\n",
    "# fig, ax = pyplot.subplots()\n",
    "# grouped = df.groupby('label')\n",
    "# print(X_1.shape, y_1.shape)\n",
    "# for key, group in grouped:\n",
    "#     group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "# pyplot.show()\n",
    "\n",
    "res = load_iris(return_X_y=True)\n",
    "\n",
    "X_2,y_2 = res\n",
    "y_2 = y_2.reshape((len(y_2), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 120), (1, 120), (4, 30), (1, 30))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = split_dataset(X_2,y_2)\n",
    "\n",
    "train_y = train_y.reshape((1, len(train_y)))\n",
    "test_y = test_y.reshape((1, len(test_y)))\n",
    "\n",
    "# normalize_data\n",
    "train_X, test_X, means, std_dev = normalize_data(train_X, test_X)\n",
    "\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Cost after iteration 0: 0.781158\n",
      "Cost after iteration 100: -0.768156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/svp/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "/home/svp/.local/lib/python3.6/site-packages/ipykernel_launcher.py:36: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/svp/.local/lib/python3.6/site-packages/ipykernel_launcher.py:58: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/svp/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 200: nan\n",
      "Cost after iteration 300: nan\n",
      "Cost after iteration 400: nan\n",
      "Cost after iteration 500: nan\n",
      "Cost after iteration 600: nan\n",
      "Cost after iteration 700: nan\n",
      "Cost after iteration 800: nan\n",
      "Cost after iteration 900: nan\n",
      "Cost after iteration 1000: nan\n",
      "Cost after iteration 1100: nan\n",
      "Cost after iteration 1200: nan\n",
      "Cost after iteration 1300: nan\n",
      "Cost after iteration 1400: nan\n",
      "Cost after iteration 1500: nan\n",
      "Cost after iteration 1600: nan\n",
      "Cost after iteration 1700: nan\n",
      "Cost after iteration 1800: nan\n",
      "Cost after iteration 1900: nan\n",
      "Cost after iteration 2000: nan\n",
      "Cost after iteration 2100: nan\n",
      "Cost after iteration 2200: nan\n",
      "Cost after iteration 2300: nan\n",
      "Cost after iteration 2400: nan\n",
      "Cost after iteration 2500: nan\n",
      "Cost after iteration 2600: nan\n",
      "Cost after iteration 2700: nan\n",
      "Cost after iteration 2800: nan\n",
      "Cost after iteration 2900: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f08c5b210b8>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "description = [{\"layer_size\" : 100, \"activation\" : \"relu\"},\n",
    "               {\"layer_size\" : 50, \"activation\" : \"relu\"},\n",
    "               {\"layer_size\" : 10, \"activation\" : \"relu\"},\n",
    "               {\"layer_size\" : 1, \"activation\" : \"sigmoid\"}]\n",
    "\n",
    "model = NN(description,4,\"cross_entropy_sigmoid\", train_X, train_y, learning_rate=0.0005)\n",
    "\n",
    "history = model.train(3000)\n",
    "\n",
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the training set is = 0.9912087912087912\n",
      "Accuracy of the model on the test set is = 0.9912280701754386\n"
     ]
    }
   ],
   "source": [
    "acc = model.calculate_accuracy(train_X, train_y)\n",
    "print(\"Accuracy of the model on the training set is = {}\".format(acc))\n",
    "\n",
    "acc = model.calculate_accuracy(test_X, test_y)\n",
    "print(\"Accuracy of the model on the test set is = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
